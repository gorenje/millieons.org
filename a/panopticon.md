---
permalink: /a/panopticon
---

## Panopticon

Based on two pieces by [Nick Bostrom](https://nickbostrom.com/):

- [How vulnerable is the world?](https://aeon.co/essays/none-of-our-technologies-has-managed-to-destroy-humanity-yet)
- and the [original paper](https://onlinelibrary.wiley.com/doi/full/10.1111/1758-5899.12718)

The article argues that we need a sophisticated global [panopticon](https://en.wikipedia.org/wiki/Panopticon) to avoid complete global human destruction. The basic argument is that as we keep inventing new technologies, eventually we will invent something that has the potential to wipe all humans off the face of the earth. This was the case with nuclear weapons however nuclear weapons are non-trivial to create. The difficulty level has basically prevented complete destruction by nuclear weapons.

What Nick Bostrom is talking about are a made-in-the-kitchen technology that can have the same or great effect as nuclear weapons. So that if the technology made it into the mainstream, then we can basically say good night.

The potential for disaster is presented by a class of actors - as named by the articles - called *apocalyptic residual*:

> [...] and there are some actors (‘the apocalyptic residual’) who would act in ways that destroy civilization even at high cost to themselves.

It is this apocalyptic residual from which we need to protect ourselves from,  and these articles are very well argued and make a solid case for world wide surveillance and a global government to take charge.

It's the best arguments, that I've read, for a [1984](https://en.wikipedia.org/wiki/Nineteen_Eighty-Four) scenario. However what are the potential dangers of such a system? Besides the obvious potential for total global corruption when there is a single global government.

One could argue that the measures advocated could lead to humankind being less resilient to virus mutations or other evolutionary crisis because of biological human harmonisation under a system that makes all humans behave the same.

The constant state of potentially being watched, at any time, would have certainly have negative emotional impact on certain parts of the society. This could lead to an increase in depression and suicide. Of course, after one or two generations this might well become the new "normal" and no one will know the difference.

Since the main aim of the articles is to ensure the longevity of humans,  from another perspective, the question becomes what will lead to human extinction faster: the invention of a table-top technology that can wipe us out or the measures we take to prevent this table-top technology from being invented?

It should also be said that humans are very resilient: humans have, over the eons, come and gone, sometimes fewer and sometimes more, but somehow have always survived. So will we probably continue to survive. (Although one could also argue that in comparison to a lot of other lifeforms on this planet, we haven't even evolved out of our evolutionary nappies.)

Even if this means leaving native tribes in the Amazoners and [PNG](https://en.wikipedia.org/wiki/Papua_New_Guinea) alone so that they can "seed" the next round of human evolution. These tribes are the last humans who still know how to live from nature and survive in a world where you don't have electricity or creature comforts. 

Although, they also seem to want to [annihilate themselves too](https://www.theguardian.com/world/2021/feb/27/tribal-conflict-worsens-in-papua-new-guinea-as-firearms-rewrite-the-rules). 

Is it worth giving up our creativity, individualities and freedoms for some - potentially - longer time with less freedoms? Or continue as-is and enjoy - at least some (we're by no stretch as free as we could be) - of the freedoms until something bad happens even if that means humans will cease to existing sooner rather than later? Another issue with this article is the idea of a central government. What happens if they make a bad decisions on a vaccine and kill halve the worlds population? 

In certain sense, this is all simply too much [prediction](/w/predictions), making it fiction.
