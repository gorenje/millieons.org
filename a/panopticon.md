---
permalink: /a/panopticon
---

## Panopticon

Listen to [How vulnerable is the world? by Nick Bostrom](https://aeon.co/essays/none-of-our-technologies-has-managed-to-destroy-humanity-yet) - basically there is no way to protect against a technology that can kill us all. The article argues that we need a sophisticated global panopticon - i.e. world  wide surveillance and a global governance. Crazy stuff. [longer version](https://onlinelibrary.wiley.com/doi/full/10.1111/1758-5899.12718) - "and there are some actors (‘the apocalyptic residual’) who would act in ways that destroy civilization even at high cost to themselves." - the apocalyptic residual! - this is basically a piece that advocates global panopticon, global government and global surveillance and provides very good arguments for all these. Stating for example: "For instance, even those who are highly suspicious of government surveillance would presumably favour a large increase in such surveillance *if* it were truly necessary to prevent occasional region‐wide destruction." It's scary to think that an Oxford Professor would provide the basis for panopticon. One could argue that the measures the author advocates could lead to humankind being less resilient to virus mutations or other evolutionary crisis because of biological human harmonisation under a system that makes all humans behave the same. And potentially leading to an increase in depression and suicide. Then it becomes a question of time before human are extinct. Either we could extinct because we find a technology black ball or our attempts to prevent us finding the technology black ball kills us all! 

The irony of it all. Strangely the perfectly simply solution to this closed-loop argument is simply to realise that humans have, over the centuries, come and gone, fewer and more, but have always survived. So will we continue to survive. Even if this means leaving native tribes in the amazons and [PNG](https://en.wikipedia.org/wiki/Papua_New_Guinea) alone so that they can "seed" the next round of human evolution. These tribes are the last humans who still know how to live from nature and survive in a world where you don't have electricity or creature comforts. Although, they also seem to what to [annihilate themselves too](https://www.theguardian.com/world/2021/feb/27/tribal-conflict-worsens-in-papua-new-guinea-as-firearms-rewrite-the-rules). So the closed loop argument comes down to a question of time: which will cause the extinction of the human race faster? A global-panopticon or a black ball technology? Is it worth giving up our creativity, individualities and freedoms for some - potentially - longer time with less freedoms? Or continue as-is and enjoy - at least some (we're by no stretch as free as we could be) - of the freedoms until something bad happens even if that means humans will cease to existing sooner rather than later? Another issue with this article is the idea of a central government. What happens if they make a bad decisions on a vaccine and kill halve the worlds population? It's all too much prediction, making it fiction!
