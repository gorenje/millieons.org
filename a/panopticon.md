---
permalink: /a/panopticon
---

## Panopticon

Based on two pieces by [Nick Bostrom](https://nickbostrom.com/):

- [How vulnerable is the world?](https://aeon.co/essays/none-of-our-technologies-has-managed-to-destroy-humanity-yet)
- and the [original paper](https://onlinelibrary.wiley.com/doi/full/10.1111/1758-5899.12718)

The article argues that we need a sophisticated global [panopticon](https://en.wikipedia.org/wiki/Panopticon) to avoid complete global human destruction. The basic argument is that as we keep inventing new technologies, eventually we will invent something that has the potential to wipe all humans off the face of the earth. This was the case with nuclear weapons however nuclear weapons are non-trivial to create. The difficulty level has basically prevented complete destruction by nuclear weapons.

What Nick Bostrom is talking about are a made-in-the-kitchen technology that can have the same or great effect as nuclear weapons. So that if the technology made it into the mainstream, then we can basically say good night.

The potential for disaster is presented by a class of actors - as named by the articles - called *apocalyptic residual*:

> [...] and there are some actors (‘the apocalyptic residual’) who would act in ways that destroy civilization even at high cost to themselves.

It is this apocalyptic residual from which we need to protect ourselves from,  and these articles are very well argued and make a solid case for world wide surveillance and a global government to take charge.

It's the best arguments, that I've read, for a [1984](https://en.wikipedia.org/wiki/Nineteen_Eighty-Four) scenario. However what are the potential dangers of such a system? Besides the obvious potential for total global corruption when there is a single global government.

One could argue that the measures advocated could lead to humankind being less resilient to virus mutations or other evolutionary crisis because of biological human harmonisation under a system that makes all humans behave the same.

The constant state of potentially being watched, at any time, would have certainly have negative emotional impact on certain parts of the society. This could lead to an increase in depression and suicide. Of course, after one or two generations this might well become the new "normal" and no one will know the difference.

### Longevity

Since the main aim of the articles is to ensure the longevity of humans,  from another perspective, the question becomes what will lead to human extinction faster: the invention of a table-top technology that can wipe us out or the measures we take to prevent this table-top technology from being invented?

What the articles potentially also miss is an invention that might wipe out a majority but not all. Leading to a world with less conflict. Or even better, what would happen if we invented a technology that would lead to world peace and harmony? One should be [fearless](/w/fearless) enough to pose these questions. 

It should also be said that humans are very resilient: humans have, over the eons, come and gone, sometimes fewer and sometimes more, but somehow have always survived. So will we probably continue to survive. (Although one could also argue that in comparison to a lot of other lifeforms on this planet, we haven't even evolved out of our evolutionary nappies.)

Even if this means leaving native tribes in the Amazons and Papua New Guinea alone so that they could act "seed" the next round of human evolution. These tribes are the last humans who still know how to live with nature and survive in a world where you don't have electricity or creature comforts.

Although, unfortunately, they also seem to want to [annihilate themselves](https://www.theguardian.com/world/2021/feb/27/tribal-conflict-worsens-in-papua-new-guinea-as-firearms-rewrite-the-rules). Which does raise the question whether modern weapons are a kind of apocalyptic tool for native tribes?

So is it really worth giving up our creativity, individualism and freedoms for some potential threat might never materialise? For those that have read 1984, this threat seems to be similar to the enemies of Oceania that never quite get defeated and neither do they defeat Oceania. Thus the basis for restriction and constraints is maintained.

However perhaps it's just a little too much [prediction](/w/predictions), making it fiction.
